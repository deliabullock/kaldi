------------------stage 0 done--------------------

------------------stage 1 done--------------------

------------------stage 2 done--------------------

------------------stage 3 done--------------------

------------------stage 4 done--------------------

------------------stage 5 done--------------------

------------------stage 6 done--------------------

------------------stage 7 done--------------------

------------------stage 8 done--------------------

------------------stage 9 done--------------------

------------------stage 10 done--------------------

------------------stage 11 done--------------------

------------------stage 12 done--------------------

------------------stage 13 done--------------------

------------------stage 14 done--------------------

------------------stage 15 done--------------------

------------------stage 16 done--------------------

local/chain/run_tdnn_lstm.sh --stage 17
local/chain/run_tdnn_lstm.sh: line 83: [: missing `]'
local/chain/run_tdnn_lstm.sh: creating neural net configs using the xconfig parser
tree-info exp/chain_cleaned/tree_bi/tree 
steps/nnet3/xconfig_to_configs.py --xconfig-file exp/chain_cleaned/tdnn_lstm1a_sp_bi/configs/network.xconfig --config-dir exp/chain_cleaned/tdnn_lstm1a_sp_bi/configs/
2017-04-03 03:10:32,904 [steps/nnet3/chain/train.py:33 - <module> - INFO ] Starting chain model trainer (train.py)
2017-04-03 03:10:32,991 [steps/nnet3/chain/train.py:254 - train - INFO ] Arguments for the experiment
{'add_layers_period': 2,
 'alignment_subsampling_factor': 3,
 'apply_deriv_weights': False,
 'background_polling_time': 60,
 'chunk_left_context': 40,
 'chunk_right_context': 0,
 'chunk_width': 150,
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'command': 'run.pl --max-jobs-run 2',
 'deriv_truncate_margin': 10,
 'dir': 'exp/chain_cleaned/tdnn_lstm1a_sp_bi',
 'dropout_schedule': None,
 'egs_command': 'queue.pl',
 'egs_dir': None,
 'egs_opts': '--frames-overlap-per-eg 0',
 'egs_stage': 0,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/train_cleaned_sp_hires_comb',
 'final_effective_lrate': 0.0001,
 'frame_subsampling_factor': 3,
 'frames_per_iter': 1500000,
 'initial_effective_lrate': 0.001,
 'l2_regularize': 5e-05,
 'lat_dir': 'exp/chain_cleaned/tri3_cleaned_train_cleaned_sp_comb_lats',
 'leaky_hmm_coefficient': 0.1,
 'left_deriv_truncate': None,
 'left_tolerance': 5,
 'lm_opts': '--num-extra-lm-states=2000',
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_param_change': 2.0,
 'momentum': 0.0,
 'num_chunk_per_minibatch': 128,
 'num_epochs': 4,
 'num_jobs_final': 2,
 'num_jobs_initial': 2,
 'online_ivector_dir': 'exp/nnet3_cleaned/ivectors_train_cleaned_sp_hires_comb',
 'preserve_model_interval': 100,
 'presoftmax_prior_scale_power': -0.25,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'right_tolerance': 5,
 'samples_per_iter': 400000,
 'shrink_saturation_threshold': 0.4,
 'shrink_value': 0.99,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'transform_dir': 'exp/chain_cleaned/tri3_cleaned_train_cleaned_sp_comb_lats',
 'tree_dir': 'exp/chain_cleaned/tree_bi',
 'truncate_deriv_weights': 0,
 'use_gpu': True,
 'xent_regularize': 0.1}
2017-04-03 03:10:34,666 [steps/nnet3/chain/train.py:296 - train - INFO ] Creating phone language-model
2017-04-03 03:11:38,501 [steps/nnet3/chain/train.py:301 - train - INFO ] Creating denominator FST
copy-transition-model exp/chain_cleaned/tree_bi/final.mdl exp/chain_cleaned/tdnn_lstm1a_sp_bi/0.trans_mdl 
LOG (copy-transition-model[5.0.37~1-e227e]:main():copy-transition-model.cc:62) Copied transition model.
2017-04-03 03:11:44,782 [steps/nnet3/chain/train.py:305 - train - INFO ] Initializing a basic network for estimating preconditioning matrix
2017-04-03 03:11:45,284 [steps/nnet3/chain/train.py:318 - train - INFO ] Generating egs
steps/nnet3/chain/get_egs.sh --frames-overlap-per-eg 0 --cmd run.pl --max-jobs-run 2 --cmvn-opts --norm-means=false --norm-vars=false --feat-type raw --transform-dir exp/chain_cleaned/tri3_cleaned_train_cleaned_sp_comb_lats --online-ivector-dir exp/nnet3_cleaned/ivectors_train_cleaned_sp_hires_comb --left-context 54 --right-context 21 --valid-left-context  --valid-right-context  --left-tolerance 5 --right-tolerance 5 --frame-subsampling-factor 3 --alignment-subsampling-factor 3 --stage 0 --frames-per-iter 1500000 --frames-per-eg 150 --srand 0 data/train_cleaned_sp_hires_comb exp/chain_cleaned/tdnn_lstm1a_sp_bi exp/chain_cleaned/tri3_cleaned_train_cleaned_sp_comb_lats exp/chain_cleaned/tdnn_lstm1a_sp_bi/egs
feat-to-len 'scp:head -n 10 data/train_cleaned_sp_hires_comb/feats.scp|' ark,t:- 
utils/data/get_utt2dur.sh: data/train_cleaned_sp_hires_comb/utt2dur already exists with the expected length.  We won't recompute it.
File data/train_cleaned_sp_hires_comb/utt2uniq exists, so augmenting valid_uttlist to
include all perturbed versions of the same 'real' utterances.
steps/nnet3/chain/get_egs.sh: feature type is raw
feat-to-dim scp:exp/nnet3_cleaned/ivectors_train_cleaned_sp_hires_comb/ivector_online.scp - 
steps/nnet3/chain/get_egs.sh: working out number of frames of training data
feat-to-len 'scp:head -n 10 data/train_cleaned_sp_hires_comb/feats.scp|' ark,t:- 
steps/nnet3/chain/get_egs.sh: working out feature dim
steps/nnet3/chain/get_egs.sh: creating processes safe guards
steps/nnet3/chain/get_egs.sh: max files open:256
steps/nnet3/chain/get_egs.sh: num_archives_inter:148
steps/nnet3/chain/get_egs.sh: num archives total:148
steps/nnet3/chain/get_egs.sh: max files from user:1024
steps/nnet3/chain/get_egs.sh: creating 148 archives, each with 9969 egs, with
steps/nnet3/chain/get_egs.sh:   150 labels per example, and (left,right) context = (54,21)
steps/nnet3/chain/get_egs.sh: copying training lattices
steps/nnet3/chain/get_egs.sh: Getting validation and training subset examples.
steps/nnet3/chain/get_egs.sh: ... extracting validation and training-subset alignments.
... Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/chain/get_egs.sh: Generating training examples on disk
steps/nnet3/chain/get_egs.sh: recombining and shuffling order of archives on disk: 2
here?
steps/nnet3/chain/get_egs.sh: removing temporary archives
steps/nnet3/chain/get_egs.sh: removing temporary lattices
steps/nnet3/chain/get_egs.sh: removing temporary alignments and transforms
steps/nnet3/chain/get_egs.sh: Finished preparing training examples
2017-04-03 06:14:19,416 [steps/nnet3/chain/train.py:360 - train - INFO ] Computing the preconditioning matrix for input features
2017-04-03 06:16:18,663 [steps/nnet3/chain/train.py:368 - train - INFO ] Preparing the initial acoustic model.
2017-04-03 06:16:21,961 [steps/nnet3/chain/train.py:405 - train - INFO ] Training will run for 4 epochs = 888 iterations
2017-04-03 06:16:21,961 [steps/nnet3/chain/train.py:429 - train - INFO ] On iteration 0, learning rate is 0.002 and shrink value is 0.99.
2017-04-03 06:16:21,961 [steps/nnet3/chain/train.py:431 - train - INFO ] About to train
2017-04-03 06:16:21,961 [steps/libs/nnet3/train/chain_objf/acoustic_model.py:236 - train_one_iteration - INFO ] Training neural net (pass 0)
2017-04-03 06:16:22,010 [steps/libs/nnet3/train/chain_objf/acoustic_model.py:317 - train_one_iteration - INFO ] On iteration 0, learning rate is 0.002 and shrink value is 0.99.
run.pl: job failed, log is in exp/chain_cleaned/tdnn_lstm1a_sp_bi/log/train.0.2.log
run.pl: job failed, log is in exp/chain_cleaned/tdnn_lstm1a_sp_bi/log/train.0.1.log
Traceback (most recent call last):
  File "steps/nnet3/chain/train.py", line 534, in main
    train(args, run_opts, background_process_handler)
  File "steps/nnet3/chain/train.py", line 464, in train
    background_process_handler=background_process_handler)
  File "steps/libs/nnet3/train/chain_objf/acoustic_model.py", line 337, in train_one_iteration
    cache_io_opts=cache_io_opts, run_opts=run_opts)
  File "steps/libs/nnet3/train/chain_objf/acoustic_model.py", line 211, in train_new_models
    "iteration {0}".format(iter))
Exception: There was error during training iteration 0
steps/nnet3/chain/train.py --stage -10 --cmd run.pl --max-jobs-run 2 --feat.online-ivector-dir exp/nnet3_cleaned/ivectors_train_cleaned_sp_hires_comb --feat.cmvn-opts --norm-means=false --norm-vars=false --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient 0.1 --chain.l2-regularize 0.00005 --chain.apply-deriv-weights false --chain.lm-opts=--num-extra-lm-states=2000 --egs.dir  --egs.opts --frames-overlap-per-eg 0 --egs.chunk-width 150 --egs.chunk-left-context 40 --egs.chunk-right-context 0 --trainer.num-chunk-per-minibatch 128 --trainer.frames-per-iter 1500000 --trainer.max-param-change 2.0 --trainer.num-epochs 4 --trainer.deriv-truncate-margin 10 --trainer.optimization.shrink-value 0.99 --trainer.optimization.num-jobs-initial 2 --trainer.optimization.num-jobs-final 2 --trainer.optimization.initial-effective-lrate 0.001 --trainer.optimization.final-effective-lrate 0.0001 --trainer.optimization.momentum 0.0 --cleanup.remove-egs true --feat-dir data/train_cleaned_sp_hires_comb --tree-dir exp/chain_cleaned/tree_bi --lat-dir exp/chain_cleaned/tri3_cleaned_train_cleaned_sp_comb_lats --dir exp/chain_cleaned/tdnn_lstm1a_sp_bi
['steps/nnet3/chain/train.py', '--stage', '-10', '--cmd', 'run.pl --max-jobs-run 2', '--feat.online-ivector-dir', 'exp/nnet3_cleaned/ivectors_train_cleaned_sp_hires_comb', '--feat.cmvn-opts', '--norm-means=false --norm-vars=false', '--chain.xent-regularize', '0.1', '--chain.leaky-hmm-coefficient', '0.1', '--chain.l2-regularize', '0.00005', '--chain.apply-deriv-weights', 'false', '--chain.lm-opts=--num-extra-lm-states=2000', '--egs.dir', '', '--egs.opts', '--frames-overlap-per-eg 0', '--egs.chunk-width', '150', '--egs.chunk-left-context', '40', '--egs.chunk-right-context', '0', '--trainer.num-chunk-per-minibatch', '128', '--trainer.frames-per-iter', '1500000', '--trainer.max-param-change', '2.0', '--trainer.num-epochs', '4', '--trainer.deriv-truncate-margin', '10', '--trainer.optimization.shrink-value', '0.99', '--trainer.optimization.num-jobs-initial', '2', '--trainer.optimization.num-jobs-final', '2', '--trainer.optimization.initial-effective-lrate', '0.001', '--trainer.optimization.final-effective-lrate', '0.0001', '--trainer.optimization.momentum', '0.0', '--cleanup.remove-egs', 'true', '--feat-dir', 'data/train_cleaned_sp_hires_comb', '--tree-dir', 'exp/chain_cleaned/tree_bi', '--lat-dir', 'exp/chain_cleaned/tri3_cleaned_train_cleaned_sp_comb_lats', '--dir', 'exp/chain_cleaned/tdnn_lstm1a_sp_bi']
about to train
Traceback (most recent call last):
  File "steps/nnet3/chain/train.py", line 547, in <module>
    main()
  File "steps/nnet3/chain/train.py", line 543, in main
    raise e
Exception: There was error during training iteration 0
